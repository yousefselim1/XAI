# -*- coding: utf-8 -*-
"""DSAI305_project_MidProgress_Kareem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lQKf6UF2lDLk5S2BYmfKt4Z69ha9EXyX
"""

# Install required libraries
!pip install lime shap scikit-learn numpy pandas matplotlib tensorflow pillow

# Note: After installation, restart the runtime to ensure all libraries are properly loaded.

import kagglehub

# Download latest version
path = kagglehub.dataset_download("fernando2rad/x-ray-lung-diseases-images-9-classes")

print("Path to dataset files:", path)

import os
import cv2
import numpy as np
from tqdm import tqdm

def preprocess_images(source_folder, target_folder, img_size=(256, 256)):
    categories = os.listdir(source_folder)
    for category in categories:
        img_paths = os.listdir(os.path.join(source_folder, category))
        os.makedirs(os.path.join(target_folder, category), exist_ok=True)
        for img_name in tqdm(img_paths, desc=f"Processing {category}"):
            img_path = os.path.join(source_folder, category, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale
            img_resized = cv2.resize(img, img_size)  # Resize image
            cv2.imwrite(os.path.join(target_folder, category, img_name), img_resized)  # Save preprocessed image

# Usage
source_dir = '/kaggle/input/x-ray-lung-diseases-images-9-classes'
target_dir = '/kaggle/processed/x-ray-lung-diseases-images'
preprocess_images(source_dir, target_dir)

"""## **Exploratory Data Analysis (EDA)**"""

import matplotlib.pyplot as plt
import seaborn as sns

def plot_sample_images(data_folder, num_samples=5):
    categories = os.listdir(data_folder)
    fig, axs = plt.subplots(len(categories), num_samples, figsize=(num_samples * 2, len(categories) * 3))
    for i, category in enumerate(categories):
        images = os.listdir(os.path.join(data_folder, category))[:num_samples]
        for j, image in enumerate(images):
            img_path = os.path.join(data_folder, category, image)
            img = plt.imread(img_path)
            axs[i, j].imshow(img, cmap='gray')
            axs[i, j].axis('off')
        axs[i, 0].set_ylabel(category)
    plt.tight_layout()
    plt.show()

def plot_class_distribution(data_folder):
    categories = os.listdir(data_folder)
    counts = [len(os.listdir(os.path.join(data_folder, cat))) for cat in categories]
    sns.barplot(x=categories, y=counts)
    plt.title('Class Distribution')
    plt.xticks(rotation=90)
    plt.show()

# Usage
plot_sample_images(target_dir)
plot_class_distribution(target_dir)

"""## **Setting Up Data Generators**"""

import os
import shutil
from sklearn.model_selection import train_test_split

def split_dataset(source_dir, output_dir, train_ratio=0.7, val_ratio=0.15):
    classes = os.listdir(source_dir)

    for class_name in classes:
        class_path = os.path.join(source_dir, class_name)
        images = os.listdir(class_path)
        train_val, test = train_test_split(images, test_size=1 - (train_ratio + val_ratio), random_state=42)
        train, val = train_test_split(train_val, test_size=val_ratio / (train_ratio + val_ratio), random_state=42)

        for split_name, split_data in zip(['train', 'val', 'test'], [train, val, test]):
            split_class_dir = os.path.join(output_dir, split_name, class_name)
            os.makedirs(split_class_dir, exist_ok=True)
            for img in split_data:
                src = os.path.join(class_path, img)
                dst = os.path.join(split_class_dir, img)
                shutil.copy(src, dst)

# Usage:
processed_source = '/kaggle/input/x-ray-lung-diseases-images-9-classes'
processed_output = '/kaggle/working/xray_split'
split_dataset(processed_source, processed_output)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Set up augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
)

val_datagen = ImageDataGenerator(rescale=1./255)

test_datagen = ImageDataGenerator(rescale=1./255)

# Set up data generators
train_generator = train_datagen.flow_from_directory(
    directory=os.path.join(processed_output, 'train'),
    target_size=(256, 256),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=32,
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    directory=os.path.join(processed_output, 'val'),
    target_size=(256, 256),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

test_generator = test_datagen.flow_from_directory(
    directory=os.path.join(processed_output, 'test'),
    target_size=(256, 256),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

# Example: Pneumothorax vs. Normal
selected_classes = ['Pneumothorax', 'Normal']

import tensorflow as tf
from tensorflow.keras import layers, models

def build_model(input_shape=(256, 256, 1)):
    model = models.Sequential()

    # Input layer
    model.add(layers.Input(shape=input_shape))

    # Layer 1: Conv2D
    model.add(layers.Conv2D(256, (3, 3), activation='relu', strides=2))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))

    # Layer 2: Conv2D
    model.add(layers.Conv2D(128, (5, 5), activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))

    # Layer 3: Conv2D
    model.add(layers.Conv2D(256, (7, 7), activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))

    # Layer 4: Conv2D
    model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))

    # Layer 5: Conv2D
    model.add(layers.Conv2D(64, (1, 1), activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(1, 1)))

    # Flatten
    model.add(layers.Flatten())
    model.add(layers.Dropout(0.5))

    # Dense layers
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dropout(0.5))

    # Output layer
    model.add(layers.Dense(1, activation='sigmoid'))  # 9 classes

    return model

# Initialize the model
model = build_model()
model.summary()

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

import os

print(os.listdir('/kaggle/working/xray_split/train'))  # Print to confirm folder names

selected_classes = [
    '00 Anatomia Normal',
    '01 Processos Inflamatórios Pulmonares (Pneumonia)'
]

train_generator = train_datagen.flow_from_directory(
    '/kaggle/working/xray_split/train',
    target_size=(256, 256),
    color_mode='grayscale',
    classes=selected_classes,
    class_mode='binary',
    batch_size=32
)

val_generator = val_datagen.flow_from_directory(
    '/kaggle/working/xray_split/val',
    target_size=(256, 256),
    color_mode='grayscale',
    classes=selected_classes,
    class_mode='binary',
    batch_size=32
)

test_generator = test_datagen.flow_from_directory(
    '/kaggle/working/xray_split/val',
    target_size=(256, 256),
    color_mode='grayscale',
    classes=selected_classes,
    class_mode='binary',
    batch_size=32
)

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    train_generator,
    epochs=30,
    validation_data=val_generator,
    callbacks=[early_stop]
)

model.save('/kaggle/working/my_trained_model.h5')

loss, acc = model.evaluate(val_generator)
print(f"Validation Accuracy: {acc:.4f}, Loss: {loss:.4f}")

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs. Validation Accuracy')
plt.show()

test_loss, test_acc = model.evaluate(test_generator)

print(f"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}")

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

axes[0].plot(history.history['accuracy'], label='train')
axes[0].plot(history.history['val_accuracy'], label='val')
axes[0].set_title('Model Accuracy')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Accuracy')
axes[0].legend()

axes[1].plot(history.history['loss'], label='train')
axes[1].plot(history.history['val_loss'], label='val')
axes[1].set_title('Model Loss')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Loss')
axes[1].legend()

plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

y_true = test_generator.classes

y_pred = model.predict(test_generator)
y_pred = np.round(y_pred).astype(int)

cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues', cbar=True,
            xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.title('Confusion Matrix')
plt.show()

import pandas as pd
from sklearn.metrics import confusion_matrix
import numpy as np
from tensorflow.keras.models import load_model

model = load_model('/kaggle/working/my_trained_model.h5')

def calculate_metrics(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    TP = cm[1, 1]
    TN = cm[0, 0]
    FP = cm[0, 1]
    FN = cm[1, 0]
    accuracy = (TP + TN) / (TP + TN + FP + FN) * 100
    return TP, TN, FP, FN, accuracy


results = []


selected_classes = [
    '00 Anatomia Normal',
    '01 Processos Inflamatórios Pulmonares (Pneumonia)'
]


resolutions = [(120, 120), (150, 150), (180, 180), (224, 224)]
for resolution in resolutions:
    img_size = resolution



    y_true_train = train_generator.classes
    y_pred_train = model.predict(train_generator)
    y_pred_train = np.round(y_pred_train).astype(int)


    TP_train, TN_train, FP_train, FN_train, acc_train = calculate_metrics(y_true_train, y_pred_train)

    y_true_test = test_generator.classes
    y_pred_test = model.predict(test_generator)
    y_pred_test = np.round(y_pred_test).astype(int)

    TP_test, TN_test, FP_test, FN_test, acc_test = calculate_metrics(y_true_test, y_pred_test)

    results.append([ img_size[0], img_size[1], len(train_generator.classes), TP_train, TN_train, FP_train, FN_train, acc_train])
    results.append([ img_size[0], img_size[1], len(test_generator.classes), TP_test, TN_test, FP_test, FN_test, acc_test])

columns = ['Train data', 'Resolution', 'Data size', 'TP', 'TN', 'FP', 'FN', 'Acc (%)']

df = pd.DataFrame(results, columns=columns)

print(df)

results.append([1, img_size[0], img_size[1], len(train_generator.classes), TP_train, TN_train, FP_train, FN_train, acc_train])
results.append([0, img_size[0], img_size[1], len(test_generator.classes), TP_test, TN_test, FP_test, FN_test, acc_test])

columns = ['S.No', 'Model', 'Train data', 'Resolution', 'Data size', 'TP', 'TN', 'FP', 'FN', 'Acc (%)']

"""# LIME"""

from lime import lime_image
from skimage.segmentation import mark_boundaries
import matplotlib.pyplot as plt
import numpy as np


explainer = lime_image.LimeImageExplainer()

def model_predict(images):
    if images.ndim == 4 and images.shape[-1] == 3:
        images = images.mean(axis=-1, keepdims=True)
    elif images.ndim == 3:
        images = np.expand_dims(images, -1)

    if images.shape[-1] != 1:
        images = np.expand_dims(images, -1)

    return model.predict(images)

def get_examples_per_digit(x_test, y_test):
    examples = {}
    for i in range(len(x_test)):
        true_label = np.argmax(y_test[i])
        if true_label not in examples:
            examples[true_label] = x_test[i]
        if len(examples) == 10:
            break
    return examples

x_test, y_test = next(test_generator)

digit_examples = get_examples_per_digit(x_test, y_test)

plt.figure(figsize=(15, 20))

for digit in sorted(digit_examples.keys()):
    image = digit_examples[digit]

    explanation = explainer.explain_instance(
        image.squeeze(),
        model_predict,
        top_labels=1,
        hide_color=0,
        num_samples=1000
    )

    pred = model.predict(image[np.newaxis, ...])
    pred_class = np.argmax(pred)
    pred_prob = np.max(pred)

    temp, mask = explanation.get_image_and_mask(
        pred_class,
        positive_only=True,
        num_features=5,
        hide_rest=False
    )

    plt.subplot(5, 4, digit*2 + 1)
    plt.imshow(image.squeeze(), cmap='gray')
    plt.title(f'Digit {digit}\nPred: {pred_class} ({pred_prob:.2f})')
    plt.axis('off')

    plt.subplot(5, 4, digit*2 + 2)
    plt.imshow(mark_boundaries(temp, mask))
    plt.title('Important Features')
    plt.axis('off')

plt.tight_layout()
plt.suptitle('LIME Explanations for MNIST Digits', y=1.02, fontsize=16)
plt.show()

"""# **SHAP**"""

digit_indices = {digit: None for digit in range(10)}
for i in range(len(x_test)):
    true_label = np.argmax(y_test[i])
    if digit_indices[true_label] is None:
        digit_indices[true_label] = i
    if all(v is not None for v in digit_indices.values()):
        break

import shap
import numpy as np

x_train, y_train = next(train_generator)
for _ in range(len(train_generator) - 1):
    x_batch, y_batch = next(train_generator)
    x_train = np.concatenate([x_train, x_batch])
    y_train = np.concatenate([y_train, y_batch])
num_background_samples = 25
background_indices = np.random.choice(x_train.shape[0], num_background_samples, replace=False)
background = x_train[background_indices]
test_images = np.array([digit_examples[i] for i in range(len(digit_examples))])
explainer = shap.DeepExplainer(model, background)
shap_values = explainer.shap_values(test_images)

shap.image_plot(shap_values, -test_images)

"""# Second Model"""

def build_model2(input_shape=(224, 224, 3), num_classes=2):
    base_model = VGG16(weights="imagenet", include_top=False, input_tensor=Input(shape=input_shape))
    base_model.trainable = False

    head = base_model.output
    head = AveragePooling2D(pool_size=(4, 4))(head)
    head = Flatten()(head)
    head = Dense(64, activation='relu')(head)
    head = Dropout(0.5)(head)
    head = Dense(num_classes, activation='softmax')(head)

    model = Model(inputs=base_model.input, outputs=head)
    return model