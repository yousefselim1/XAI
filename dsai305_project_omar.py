# -*- coding: utf-8 -*-
"""DSAI305_project_omar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sf2gRWhP0epBZNmX4iZSvBdyGWaiB3bB
"""



# Install required libraries
!pip install lime shap scikit-learn numpy pandas matplotlib tensorflow pillow

# Note: After installation, restart the runtime to ensure all libraries are properly loaded.

from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.applications import VGG19
from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

import kagglehub

# Download latest version
path = kagglehub.dataset_download("fernando2rad/x-ray-lung-diseases-images-9-classes")

print("Path to dataset files:", path)

"""## **Data Preprocessing**"""

import os
import cv2
import numpy as np
from tqdm import tqdm

def preprocess_images(source_folder, target_folder, img_size=(256, 256)):
    categories = os.listdir(source_folder)
    for category in categories:
        img_paths = os.listdir(os.path.join(source_folder, category))
        os.makedirs(os.path.join(target_folder, category), exist_ok=True)
        for img_name in tqdm(img_paths, desc=f"Processing {category}"):
            img_path = os.path.join(source_folder, category, img_name)
            img = cv2.imread(img_path)  # RGB by default
            img_resized = cv2.resize(img, (224, 224))
            cv2.imwrite(os.path.join(target_folder, category, img_name), img_resized)  # Save preprocessed image

# Usage
source_dir = '/kaggle/input/x-ray-lung-diseases-images-9-classes'
target_dir = '/kaggle/processed/x-ray-lung-diseases-images'
preprocess_images(source_dir, target_dir)

"""## **Exploratory Data Analysis (EDA)**"""

import matplotlib.pyplot as plt
import seaborn as sns

def plot_sample_images(data_folder, num_samples=5):
    categories = os.listdir(data_folder)
    fig, axs = plt.subplots(len(categories), num_samples, figsize=(num_samples * 2, len(categories) * 3))
    for i, category in enumerate(categories):
        images = os.listdir(os.path.join(data_folder, category))[:num_samples]
        for j, image in enumerate(images):
            img_path = os.path.join(data_folder, category, image)
            img = plt.imread(img_path)
            axs[i, j].imshow(img, cmap='gray')
            axs[i, j].axis('off')
        axs[i, 0].set_ylabel(category)
    plt.tight_layout()
    plt.show()

def plot_class_distribution(data_folder):
    categories = os.listdir(data_folder)
    counts = [len(os.listdir(os.path.join(data_folder, cat))) for cat in categories]
    sns.barplot(x=categories, y=counts)
    plt.title('Class Distribution')
    plt.xticks(rotation=90)
    plt.show()

# Usage
plot_sample_images(target_dir)
plot_class_distribution(target_dir)

"""## **Setting Up Data Generators**"""

import os
import shutil
from sklearn.model_selection import train_test_split

def split_dataset(source_dir, output_dir, train_ratio=0.7, val_ratio=0.15):
    classes = os.listdir(source_dir)

    for class_name in classes:
        class_path = os.path.join(source_dir, class_name)
        images = os.listdir(class_path)
        train_val, test = train_test_split(images, test_size=1 - (train_ratio + val_ratio), random_state=42)
        train, val = train_test_split(train_val, test_size=val_ratio / (train_ratio + val_ratio), random_state=42)

        for split_name, split_data in zip(['train', 'val', 'test'], [train, val, test]):
            split_class_dir = os.path.join(output_dir, split_name, class_name)
            os.makedirs(split_class_dir, exist_ok=True)
            for img in split_data:
                src = os.path.join(class_path, img)
                dst = os.path.join(split_class_dir, img)
                shutil.copy(src, dst)

# Usage:
processed_source = '/kaggle/input/x-ray-lung-diseases-images-9-classes'
processed_output = '/kaggle/working/xray_split'
split_dataset(processed_source, processed_output)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Set up augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
)

val_datagen = ImageDataGenerator(rescale=1./255)

test_datagen = ImageDataGenerator(rescale=1./255)

# Set up data generators
train_generator = train_datagen.flow_from_directory(
    directory=os.path.join(processed_output, 'train'),
    target_size=(224, 224),
    color_mode='rgb',  # change here
    class_mode='categorical',
    batch_size=32,
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    directory=os.path.join(processed_output, 'val'),
    target_size=(224, 224),
    color_mode='rgb',  # change here
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

test_generator = test_datagen.flow_from_directory(
    directory=os.path.join(processed_output, 'test'),
    target_size=(224, 224),
    color_mode='rgb',  # change here
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

# Example: Pneumothorax vs. Normal
selected_classes = ['Pneumothorax', 'Normal']

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from tensorflow.keras import layers, models

# def build_model(input_shape=(256, 256, 1), num_classes=9):
#     # Convert grayscale to 3-channel
#     input_layer = Input(shape=input_shape)
#     x = tf.keras.layers.Concatenate()([input_layer, input_layer, input_layer])

#     # Load base VGG16 model
#     base_model = VGG19(weights='imagenet', include_top=False, input_tensor=x)
#     base_model.trainable = False  # Freeze base model

#     # Block 1
#     x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
#     x = BatchNormalization()(x)
#     x = MaxPooling2D(pool_size=(2, 2))(x)
#     x = Dropout(0.25)(x)

#     # Block 2
#     x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
#     x = BatchNormalization()(x)
#     x = MaxPooling2D(pool_size=(2, 2))(x)
#     x = Dropout(0.25)(x)

#     # Block 3
#     x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
#     x = BatchNormalization()(x)
#     x = MaxPooling2D(pool_size=(2, 2))(x)
#     x = Dropout(0.25)(x)

#     # Flatten and Fully Connected Layers
#     x = Flatten()(x)
#     x = Dense(512, activation='relu')(x)
#     x = Dense(256, activation='relu')(x)
#     x = Dense(128, activation='relu')(x)

#     output_layer = Dense(num_classes, activation='softmax')(x)

#     model = Model(inputs=input_layer, outputs=output_layer)

#     return model

def build_model(input_shape=(224, 224, 3), num_classes=2):  # match the generator
    input_layer = Input(shape=input_shape)

    base_model = VGG19(weights='imagenet', include_top=False, input_tensor=input_layer)
    base_model.trainable = False

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(256, activation='relu')(x)
    x = Dropout(0.5)(x)

    x = Dense(128, activation='relu')(x)
    output_layer = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=input_layer, outputs=output_layer)
    return model

model = build_model()
model.compile(optimizer=Adam(learning_rate=9e-6),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.summary()

import os

print(os.listdir('/kaggle/working/xray_split/train'))  # Print to confirm folder names

selected_classes = [
    '00 Anatomia Normal',
    '01 Processos Inflamat√≥rios Pulmonares (Pneumonia)'
]

train_generator = train_datagen.flow_from_directory(
    '/kaggle/working/xray_split/train',
    target_size=(224, 224),  # Changed to (224, 224)
    color_mode='rgb',  # Changed to 'rgb'
    classes=selected_classes,
    class_mode='categorical',
    batch_size=32
)

val_generator = val_datagen.flow_from_directory(
    '/kaggle/working/xray_split/val',
    target_size=(224, 224),  # Changed to (224, 224)
    color_mode='rgb',  # Changed to 'rgb'
    classes=selected_classes,
    class_mode='categorical',
    batch_size=32
)

test_generator = test_datagen.flow_from_directory(
    '/kaggle/working/xray_split/val',
    target_size=(224, 224),  # Changed to (224, 224)
    color_mode='rgb',  # Changed to 'rgb'
    classes=selected_classes,
    class_mode='categorical',
    batch_size=32
)

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    train_generator,
    epochs=30,
    validation_data=val_generator,
    callbacks=[early_stop]
)

model.save('/kaggle/working/my_trained_model.h5')

loss, acc = model.evaluate(val_generator)
print(f"Validation Accuracy: {acc:.4f}, Loss: {loss:.4f}")

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs. Validation Accuracy')
plt.show()

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(test_generator)

print(f"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}")

# Plot accuracy and loss
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Plot Accuracy
axes[0].plot(history.history['accuracy'], label='train')
axes[0].plot(history.history['val_accuracy'], label='val')
axes[0].set_title('Model Accuracy')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Accuracy')
axes[0].legend()

# Plot Loss
axes[1].plot(history.history['loss'], label='train')
axes[1].plot(history.history['val_loss'], label='val')
axes[1].set_title('Model Loss')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Loss')
axes[1].legend()

plt.tight_layout()
plt.show(
)

"""# LIME"""

from lime import lime_image
from skimage.segmentation import mark_boundaries
import matplotlib.pyplot as plt
import numpy as np


## Prepare LIME Explainer
explainer = lime_image.LimeImageExplainer()

# Wrapper function to make model compatible with LIME
def model_predict(images):
    # The model expects images in the shape (batch_size, 224, 224, 3)
    # LIME might pass images with shape (batch_size, 224, 224) or (batch_size, 224, 224, 3)
    # So, we need to ensure the images are in the correct shape before prediction.

    # If the images are grayscale (shape (batch_size, 224, 224)),
    # we need to convert them to RGB by stacking the grayscale channel three times.
    if images.ndim == 3:
        images = np.stack([images, images, images], axis=-1)

    # If the images are already RGB (shape (batch_size, 224, 224, 3)),
    # no further processing is needed.
    # If images have an alpha channel (4 channels), remove it
    if images.shape[-1] == 4:
        images = images[..., :3]

    # Make predictions using the model
    return model.predict(images)

## Find One Example of Each Digit
def get_examples_per_digit(x_test, y_test):
    examples = {}
    for i in range(len(x_test)):
        true_label = np.argmax(y_test[i])
        if true_label not in examples:
            examples[true_label] = x_test[i]
        if len(examples) == 10:  # We have all digits 0-9
            break
    return examples

x_test, y_test = next(test_generator)

# Now call the function with the loaded data
digit_examples = get_examples_per_digit(x_test, y_test)

## Generate and Visualize Explanations for All Digits
plt.figure(figsize=(15, 20))

for digit in sorted(digit_examples.keys()):
    image = digit_examples[digit]

    # Explain the prediction
    explanation = explainer.explain_instance(
        image.squeeze(),  # Remove channel dimension for LIME
        model_predict,
        top_labels=1,
        hide_color=0,
        num_samples=1000
    )

    # Get prediction info
    pred = model.predict(image[np.newaxis, ...])
    pred_class = np.argmax(pred)
    pred_prob = np.max(pred)

    # Get explanation image
    temp, mask = explanation.get_image_and_mask(
        pred_class,
        positive_only=True,
        num_features=5,
        hide_rest=False
    )

    # Plot original image
    plt.subplot(5, 4, digit*2 + 1)
    plt.imshow(image.squeeze(), cmap='gray')
    plt.title(f'Digit {digit}\nPred: {pred_class} ({pred_prob:.2f})')
    plt.axis('off')

    # Plot explanation
    plt.subplot(5, 4, digit*2 + 2)
    plt.imshow(mark_boundaries(temp, mask))
    plt.title('Important Features')
    plt.axis('off')

plt.tight_layout()
plt.suptitle('LIME Explanations for MNIST Digits', y=1.02, fontsize=16)
plt.show()

"""# **SHAP**"""

import shap
import numpy as np

# Get one clean example of each digit
digit_indices = {digit: None for digit in range(10)}
for i in range(len(x_test)):
    true_label = np.argmax(y_test[i])
    if digit_indices[true_label] is None:
        digit_indices[true_label] = i
    if all(v is not None for v in digit_indices.values()):
        break

digit_examples = {digit: x_test[idx] for digit, idx in digit_indices.items() if idx is not None}  # Filter out None values

# Collect all training data from generator
x_train, y_train = next(train_generator)
for _ in range(len(train_generator) - 1):
    x_batch, y_batch = next(train_generator)
    x_train = np.concatenate([x_train, x_batch])
    y_train = np.concatenate([y_train, y_batch])

# Normalize training data to [0, 1]
x_train = x_train.astype(np.float32) / 255.0

# Sample a small number of background images
num_background_samples = 25
background_indices = np.random.choice(x_train.shape[0], num_background_samples, replace=False)
background = x_train[background_indices]

# Prepare test images (one per digit) and normalize
test_images = np.array([digit_examples[i] for i in range(len(digit_examples)) if i in digit_examples]) # Only select digits that are present in digit_examples
test_images = test_images.astype(np.float32) / 255.0

# Create SHAP DeepExplainer
explainer = shap.DeepExplainer(model, background)

# Compute SHAP values
shap_values = explainer.shap_values(test_images)

# Plot SHAP values
shap.image_plot(shap_values, -test_images)

"""# Second Model"""

def build_resnet50_model(input_shape=(224, 224, 3), num_classes=2):
    base_model = ResNet50(weights="imagenet", include_top=False, input_tensor=Input(shape=input_shape))
    base_model.trainable = False

    head = base_model.output
    head = GlobalAveragePooling2D()(head)
    head = Dense(64, activation='relu')(head)
    head = Dropout(0.5)(head)
    head = Dense(num_classes, activation='softmax')(head)

    model = Model(inputs=base_model.input, outputs=head)
    return model